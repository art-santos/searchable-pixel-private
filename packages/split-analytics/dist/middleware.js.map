{"version":3,"sources":["../src/middleware.ts","../src/constants.ts","../src/detector.ts","../src/tracker.ts"],"sourcesContent":["import { NextRequest, NextResponse } from 'next/server'\nimport { detectAICrawler, extractRequestMetadata, UnknownCrawlerInfo } from './detector'\nimport { CrawlerTracker, TrackerConfig } from './tracker'\nimport { CrawlerInfo } from './constants'\n\n// Global tracker instance\nlet tracker: CrawlerTracker | null = null\n\nexport interface MiddlewareConfig extends TrackerConfig {\n  // Paths to exclude from tracking\n  exclude?: string[]\n  // Paths to include (if specified, only these paths are tracked)\n  include?: string[]\n  // Whether to add custom headers for crawlers\n  addCrawlerHeaders?: boolean\n  // Custom logic to run when crawler is detected\n  onCrawlerDetected?: (request: NextRequest, crawler: CrawlerInfo | UnknownCrawlerInfo) => void | Promise<void>\n}\n\n/**\n * Create Next.js middleware for AI crawler tracking\n */\nexport function createCrawlerMiddleware(config: MiddlewareConfig) {\n  // Initialize tracker if not already done\n  if (!tracker) {\n    tracker = new CrawlerTracker(config)\n  }\n\n  return async function middleware(request: NextRequest) {\n    const startTime = Date.now()\n    \n    try {\n      // Check if path should be tracked\n      const pathname = request.nextUrl.pathname\n      \n      if (config.exclude) {\n        const shouldExclude = config.exclude.some(pattern => {\n          if (pattern.includes('*')) {\n            const regex = new RegExp(pattern.replace(/\\*/g, '.*'))\n            return regex.test(pathname)\n          }\n          return pathname.startsWith(pattern)\n        })\n        \n        if (shouldExclude) {\n          return NextResponse.next()\n        }\n      }\n      \n      if (config.include) {\n        const shouldInclude = config.include.some(pattern => {\n          if (pattern.includes('*')) {\n            const regex = new RegExp(pattern.replace(/\\*/g, '.*'))\n            return regex.test(pathname)\n          }\n          return pathname.startsWith(pattern)\n        })\n        \n        if (!shouldInclude) {\n          return NextResponse.next()\n        }\n      }\n\n      // Detect AI crawler\n      const userAgent = request.headers.get('user-agent')\n      const detection = detectAICrawler(userAgent)\n\n      if (!detection.isAICrawler || !detection.crawler) {\n        return NextResponse.next()\n      }\n\n      // Call custom handler if provided\n      if (config.onCrawlerDetected) {\n        await config.onCrawlerDetected(request, detection.crawler)\n      }\n\n      // Create response (could be modified if needed)\n      const response = NextResponse.next()\n\n      // Add custom headers if requested\n      if (config.addCrawlerHeaders) {\n        response.headers.set('X-AI-Crawler-Detected', 'true')\n        response.headers.set('X-AI-Crawler-Name', detection.crawler.bot)\n        response.headers.set('X-AI-Crawler-Company', detection.crawler.company)\n      }\n\n      // Extract metadata\n      const metadata = extractRequestMetadata({\n        headers: Object.fromEntries(request.headers.entries()),\n        url: request.url,\n        method: request.method\n      })\n\n      // Calculate response time\n      const responseTimeMs = Date.now() - startTime\n\n      // Ensure tracker is initialized (TypeScript safety)\n      if (!tracker) {\n        tracker = new CrawlerTracker(config)\n      }\n\n      // Track the event\n      const event = tracker.createEvent(\n        detection.crawler,\n        {\n          url: request.url,\n          headers: Object.fromEntries(request.headers.entries()),\n          statusCode: response.status,\n          responseTimeMs\n        },\n        metadata\n      )\n\n      // Track asynchronously to not block the response\n      tracker.track(event).catch(error => {\n        if (config.debug) {\n          console.error('[Split Analytics] Failed to track event:', error)\n        }\n      })\n\n      return response\n\n    } catch (error) {\n      // Don't let tracking errors break the application\n      if (config.debug) {\n        console.error('[Split Analytics] Middleware error:', error)\n      }\n      return NextResponse.next()\n    }\n  }\n}\n\n/**\n * Cleanup function to call when shutting down\n */\nexport function destroyTracker() {\n  if (tracker) {\n    tracker.destroy()\n    tracker = null\n  }\n} ","// Known AI crawler user agents\nexport const AI_CRAWLERS = {\n  // OpenAI\n  'GPTBot': { company: 'OpenAI', bot: 'GPTBot', category: 'ai-training' },\n  'ChatGPT-User': { company: 'OpenAI', bot: 'ChatGPT-User', category: 'ai-assistant' },\n  'CCBot': { company: 'Common Crawl', bot: 'CCBot', category: 'ai-training' },\n  \n  // Anthropic\n  'Claude-Web': { company: 'Anthropic', bot: 'Claude-Web', category: 'ai-assistant' },\n  'ClaudeBot': { company: 'Anthropic', bot: 'ClaudeBot', category: 'ai-training' },\n  \n  // Google\n  'Google-Extended': { company: 'Google', bot: 'Google-Extended', category: 'ai-training' },\n  'Googlebot': { company: 'Google', bot: 'Googlebot', category: 'search-ai' },\n  \n  // Microsoft\n  'Bingbot': { company: 'Microsoft', bot: 'Bingbot', category: 'search-ai' },\n  \n  // Others\n  'PerplexityBot': { company: 'Perplexity', bot: 'PerplexityBot', category: 'ai-search' },\n  'YouBot': { company: 'You.com', bot: 'YouBot', category: 'ai-search' },\n  'Bytespider': { company: 'ByteDance', bot: 'Bytespider', category: 'ai-training' },\n  'Diffbot': { company: 'Diffbot', bot: 'Diffbot', category: 'ai-extraction' },\n  'FacebookBot': { company: 'Meta', bot: 'FacebookBot', category: 'social-ai' },\n  'facebookexternalhit': { company: 'Meta', bot: 'facebookexternalhit', category: 'social-ai' },\n  \n  // Research/Academic\n  'Amazonbot': { company: 'Amazon', bot: 'Amazonbot', category: 'ai-assistant' },\n  'Applebot': { company: 'Apple', bot: 'Applebot', category: 'search-ai' },\n} as const\n\nexport type CrawlerInfo = typeof AI_CRAWLERS[keyof typeof AI_CRAWLERS]\n\n// Default API endpoint\nexport const DEFAULT_API_ENDPOINT = 'https://split.dev/api/crawler-events'\n\n// Batch settings\nexport const BATCH_SIZE = 10\nexport const BATCH_INTERVAL_MS = 5000 // 5 seconds\nexport const MAX_RETRY_ATTEMPTS = 3\nexport const RETRY_DELAY_MS = 1000 ","import { AI_CRAWLERS, CrawlerInfo } from './constants'\n\n// Type for unknown crawlers\nexport interface UnknownCrawlerInfo {\n  company: string\n  bot: string\n  category: string\n}\n\nexport interface CrawlerDetectionResult {\n  isAICrawler: boolean\n  crawler?: CrawlerInfo | UnknownCrawlerInfo\n  userAgent: string\n}\n\n/**\n * Detects if a user agent string belongs to an AI crawler\n */\nexport function detectAICrawler(userAgent: string | null): CrawlerDetectionResult {\n  if (!userAgent) {\n    return {\n      isAICrawler: false,\n      userAgent: ''\n    }\n  }\n\n  // Check each known crawler pattern\n  for (const [pattern, info] of Object.entries(AI_CRAWLERS)) {\n    if (userAgent.includes(pattern)) {\n      return {\n        isAICrawler: true,\n        crawler: info,\n        userAgent\n      }\n    }\n  }\n\n  // Additional checks for less specific patterns\n  const lowerUA = userAgent.toLowerCase()\n  \n  // Check for bot patterns that might indicate AI crawlers\n  const aiPatterns = [\n    'ai-crawler',\n    'ai-bot',\n    'llm-crawler',\n    'training-bot',\n    'ml-bot'\n  ]\n  \n  for (const pattern of aiPatterns) {\n    if (lowerUA.includes(pattern)) {\n      return {\n        isAICrawler: true,\n        crawler: {\n          company: 'Unknown',\n          bot: pattern,\n          category: 'unknown'\n        } as UnknownCrawlerInfo,\n        userAgent\n      }\n    }\n  }\n\n  return {\n    isAICrawler: false,\n    userAgent\n  }\n}\n\n/**\n * Extract additional metadata from the request\n */\nexport function extractRequestMetadata(request: {\n  headers: Record<string, string | string[] | undefined>\n  url?: string\n  method?: string\n}) {\n  const metadata: Record<string, any> = {}\n\n  // Extract referer\n  const referer = request.headers['referer'] || request.headers['referrer']\n  if (referer) {\n    metadata.referer = Array.isArray(referer) ? referer[0] : referer\n  }\n\n  // Extract accept headers to understand what the crawler wants\n  const accept = request.headers['accept']\n  if (accept) {\n    metadata.accept = Array.isArray(accept) ? accept.join(', ') : accept\n  }\n\n  // Extract encoding\n  const encoding = request.headers['accept-encoding']\n  if (encoding) {\n    metadata.acceptEncoding = Array.isArray(encoding) ? encoding.join(', ') : encoding\n  }\n\n  // Extract language preferences\n  const language = request.headers['accept-language']\n  if (language) {\n    metadata.acceptLanguage = Array.isArray(language) ? language[0] : language\n  }\n\n  return metadata\n} ","import { CrawlerInfo } from './constants'\nimport { UnknownCrawlerInfo } from './detector'\nimport { \n  DEFAULT_API_ENDPOINT, \n  BATCH_SIZE, \n  BATCH_INTERVAL_MS,\n  MAX_RETRY_ATTEMPTS,\n  RETRY_DELAY_MS \n} from './constants'\n\nexport interface CrawlerEvent {\n  timestamp: string\n  domain: string\n  path: string\n  crawlerName: string\n  crawlerCompany: string\n  crawlerCategory: string\n  userAgent: string\n  statusCode?: number\n  responseTimeMs?: number\n  country?: string\n  metadata?: Record<string, any>\n}\n\nexport interface TrackerConfig {\n  apiKey: string\n  apiEndpoint?: string\n  batchSize?: number\n  batchIntervalMs?: number\n  debug?: boolean\n  onError?: (error: Error) => void\n}\n\nexport class CrawlerTracker {\n  private config: Required<TrackerConfig>\n  private eventQueue: CrawlerEvent[] = []\n  private batchTimer: NodeJS.Timeout | null = null\n  private isSending = false\n\n  constructor(config: TrackerConfig) {\n    this.config = {\n      apiKey: config.apiKey,\n      apiEndpoint: config.apiEndpoint || DEFAULT_API_ENDPOINT,\n      batchSize: config.batchSize || BATCH_SIZE,\n      batchIntervalMs: config.batchIntervalMs || BATCH_INTERVAL_MS,\n      debug: config.debug || false,\n      onError: config.onError || ((error) => console.error('[Split Analytics]', error))\n    }\n  }\n\n  /**\n   * Track a crawler visit\n   */\n  async track(event: Omit<CrawlerEvent, 'timestamp'>) {\n    const fullEvent: CrawlerEvent = {\n      ...event,\n      timestamp: new Date().toISOString()\n    }\n\n    this.eventQueue.push(fullEvent)\n\n    if (this.config.debug) {\n      console.log('[Split Analytics] Event queued:', fullEvent)\n    }\n\n    // Check if we should send immediately\n    if (this.eventQueue.length >= this.config.batchSize) {\n      await this.flush()\n    } else {\n      // Schedule batch send\n      this.scheduleBatch()\n    }\n  }\n\n  /**\n   * Create a tracking event from request data\n   */\n  createEvent(\n    crawler: CrawlerInfo | UnknownCrawlerInfo,\n    request: {\n      url: string\n      headers: Record<string, string | string[] | undefined>\n      statusCode?: number\n      responseTimeMs?: number\n    },\n    metadata?: Record<string, any>\n  ): Omit<CrawlerEvent, 'timestamp'> {\n    const url = new URL(request.url)\n    \n    return {\n      domain: url.hostname,\n      path: url.pathname,\n      crawlerName: crawler.bot,\n      crawlerCompany: crawler.company,\n      crawlerCategory: crawler.category,\n      userAgent: this.getHeaderValue(request.headers['user-agent']) || '',\n      statusCode: request.statusCode,\n      responseTimeMs: request.responseTimeMs,\n      metadata\n    }\n  }\n\n  /**\n   * Schedule a batch send\n   */\n  private scheduleBatch() {\n    if (this.batchTimer) return\n\n    this.batchTimer = setTimeout(async () => {\n      this.batchTimer = null\n      if (this.eventQueue.length > 0) {\n        await this.flush()\n      }\n    }, this.config.batchIntervalMs)\n  }\n\n  /**\n   * Send all queued events\n   */\n  async flush() {\n    if (this.isSending || this.eventQueue.length === 0) return\n\n    this.isSending = true\n    const events = [...this.eventQueue]\n    this.eventQueue = []\n\n    try {\n      await this.sendBatch(events)\n    } catch (error) {\n      // Put events back in queue for retry\n      this.eventQueue.unshift(...events)\n      this.config.onError(error as Error)\n    } finally {\n      this.isSending = false\n    }\n  }\n\n  /**\n   * Send a batch of events with retry logic\n   */\n  private async sendBatch(events: CrawlerEvent[], attempt = 1): Promise<void> {\n    try {\n      const response = await fetch(this.config.apiEndpoint, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${this.config.apiKey}`,\n          'X-Split-Version': '0.1.0'\n        },\n        body: JSON.stringify({ events })\n      })\n\n      if (!response.ok) {\n        throw new Error(`API error: ${response.status} ${response.statusText}`)\n      }\n\n      if (this.config.debug) {\n        console.log(`[Split Analytics] Sent ${events.length} events`)\n      }\n    } catch (error) {\n      if (attempt < MAX_RETRY_ATTEMPTS) {\n        // Exponential backoff\n        const delay = RETRY_DELAY_MS * Math.pow(2, attempt - 1)\n        if (this.config.debug) {\n          console.log(`[Split Analytics] Retry attempt ${attempt} after ${delay}ms`)\n        }\n        await new Promise(resolve => setTimeout(resolve, delay))\n        return this.sendBatch(events, attempt + 1)\n      }\n      throw error\n    }\n  }\n\n  /**\n   * Helper to get header value\n   */\n  private getHeaderValue(header: string | string[] | undefined): string | undefined {\n    if (!header) return undefined\n    return Array.isArray(header) ? header[0] : header\n  }\n\n  /**\n   * Cleanup resources\n   */\n  destroy() {\n    if (this.batchTimer) {\n      clearTimeout(this.batchTimer)\n      this.batchTimer = null\n    }\n    // Try to send remaining events\n    this.flush().catch(() => {})\n  }\n} "],"mappings":"yaAAA,IAAAA,EAAA,GAAAC,EAAAD,EAAA,6BAAAE,EAAA,mBAAAC,IAAA,eAAAC,EAAAJ,GAAA,IAAAK,EAA0C,uBCCnC,IAAMC,EAAc,CAEzB,OAAU,CAAE,QAAS,SAAU,IAAK,SAAU,SAAU,aAAc,EACtE,eAAgB,CAAE,QAAS,SAAU,IAAK,eAAgB,SAAU,cAAe,EACnF,MAAS,CAAE,QAAS,eAAgB,IAAK,QAAS,SAAU,aAAc,EAG1E,aAAc,CAAE,QAAS,YAAa,IAAK,aAAc,SAAU,cAAe,EAClF,UAAa,CAAE,QAAS,YAAa,IAAK,YAAa,SAAU,aAAc,EAG/E,kBAAmB,CAAE,QAAS,SAAU,IAAK,kBAAmB,SAAU,aAAc,EACxF,UAAa,CAAE,QAAS,SAAU,IAAK,YAAa,SAAU,WAAY,EAG1E,QAAW,CAAE,QAAS,YAAa,IAAK,UAAW,SAAU,WAAY,EAGzE,cAAiB,CAAE,QAAS,aAAc,IAAK,gBAAiB,SAAU,WAAY,EACtF,OAAU,CAAE,QAAS,UAAW,IAAK,SAAU,SAAU,WAAY,EACrE,WAAc,CAAE,QAAS,YAAa,IAAK,aAAc,SAAU,aAAc,EACjF,QAAW,CAAE,QAAS,UAAW,IAAK,UAAW,SAAU,eAAgB,EAC3E,YAAe,CAAE,QAAS,OAAQ,IAAK,cAAe,SAAU,WAAY,EAC5E,oBAAuB,CAAE,QAAS,OAAQ,IAAK,sBAAuB,SAAU,WAAY,EAG5F,UAAa,CAAE,QAAS,SAAU,IAAK,YAAa,SAAU,cAAe,EAC7E,SAAY,CAAE,QAAS,QAAS,IAAK,WAAY,SAAU,WAAY,CACzE,EAKaC,EAAuB,uCAGvBC,EAAa,GACbC,EAAoB,IACpBC,EAAqB,EACrBC,EAAiB,ICtBvB,SAASC,EAAgBC,EAAkD,CAChF,GAAI,CAACA,EACH,MAAO,CACL,YAAa,GACb,UAAW,EACb,EAIF,OAAW,CAACC,EAASC,CAAI,IAAK,OAAO,QAAQC,CAAW,EACtD,GAAIH,EAAU,SAASC,CAAO,EAC5B,MAAO,CACL,YAAa,GACb,QAASC,EACT,UAAAF,CACF,EAKJ,IAAMI,EAAUJ,EAAU,YAAY,EAGhCK,EAAa,CACjB,aACA,SACA,cACA,eACA,QACF,EAEA,QAAWJ,KAAWI,EACpB,GAAID,EAAQ,SAASH,CAAO,EAC1B,MAAO,CACL,YAAa,GACb,QAAS,CACP,QAAS,UACT,IAAKA,EACL,SAAU,SACZ,EACA,UAAAD,CACF,EAIJ,MAAO,CACL,YAAa,GACb,UAAAA,CACF,CACF,CAKO,SAASM,EAAuBC,EAIpC,CACD,IAAMC,EAAgC,CAAC,EAGjCC,EAAUF,EAAQ,QAAQ,SAAcA,EAAQ,QAAQ,SAC1DE,IACFD,EAAS,QAAU,MAAM,QAAQC,CAAO,EAAIA,EAAQ,CAAC,EAAIA,GAI3D,IAAMC,EAASH,EAAQ,QAAQ,OAC3BG,IACFF,EAAS,OAAS,MAAM,QAAQE,CAAM,EAAIA,EAAO,KAAK,IAAI,EAAIA,GAIhE,IAAMC,EAAWJ,EAAQ,QAAQ,iBAAiB,EAC9CI,IACFH,EAAS,eAAiB,MAAM,QAAQG,CAAQ,EAAIA,EAAS,KAAK,IAAI,EAAIA,GAI5E,IAAMC,EAAWL,EAAQ,QAAQ,iBAAiB,EAClD,OAAIK,IACFJ,EAAS,eAAiB,MAAM,QAAQI,CAAQ,EAAIA,EAAS,CAAC,EAAIA,GAG7DJ,CACT,CCvEO,IAAMK,EAAN,KAAqB,CAM1B,YAAYC,EAAuB,CAJnC,KAAQ,WAA6B,CAAC,EACtC,KAAQ,WAAoC,KAC5C,KAAQ,UAAY,GAGlB,KAAK,OAAS,CACZ,OAAQA,EAAO,OACf,YAAaA,EAAO,aAAeC,EACnC,UAAWD,EAAO,WAAaE,EAC/B,gBAAiBF,EAAO,iBAAmBG,EAC3C,MAAOH,EAAO,OAAS,GACvB,QAASA,EAAO,UAAaI,GAAU,QAAQ,MAAM,oBAAqBA,CAAK,EACjF,CACF,CAKA,MAAM,MAAMC,EAAwC,CAClD,IAAMC,EAA0B,CAC9B,GAAGD,EACH,UAAW,IAAI,KAAK,EAAE,YAAY,CACpC,EAEA,KAAK,WAAW,KAAKC,CAAS,EAE1B,KAAK,OAAO,OACd,QAAQ,IAAI,kCAAmCA,CAAS,EAItD,KAAK,WAAW,QAAU,KAAK,OAAO,UACxC,MAAM,KAAK,MAAM,EAGjB,KAAK,cAAc,CAEvB,CAKA,YACEC,EACAC,EAMAC,EACiC,CACjC,IAAMC,EAAM,IAAI,IAAIF,EAAQ,GAAG,EAE/B,MAAO,CACL,OAAQE,EAAI,SACZ,KAAMA,EAAI,SACV,YAAaH,EAAQ,IACrB,eAAgBA,EAAQ,QACxB,gBAAiBA,EAAQ,SACzB,UAAW,KAAK,eAAeC,EAAQ,QAAQ,YAAY,CAAC,GAAK,GACjE,WAAYA,EAAQ,WACpB,eAAgBA,EAAQ,eACxB,SAAAC,CACF,CACF,CAKQ,eAAgB,CAClB,KAAK,aAET,KAAK,WAAa,WAAW,SAAY,CACvC,KAAK,WAAa,KACd,KAAK,WAAW,OAAS,GAC3B,MAAM,KAAK,MAAM,CAErB,EAAG,KAAK,OAAO,eAAe,EAChC,CAKA,MAAM,OAAQ,CACZ,GAAI,KAAK,WAAa,KAAK,WAAW,SAAW,EAAG,OAEpD,KAAK,UAAY,GACjB,IAAME,EAAS,CAAC,GAAG,KAAK,UAAU,EAClC,KAAK,WAAa,CAAC,EAEnB,GAAI,CACF,MAAM,KAAK,UAAUA,CAAM,CAC7B,OAASP,EAAO,CAEd,KAAK,WAAW,QAAQ,GAAGO,CAAM,EACjC,KAAK,OAAO,QAAQP,CAAc,CACpC,QAAE,CACA,KAAK,UAAY,EACnB,CACF,CAKA,MAAc,UAAUO,EAAwBC,EAAU,EAAkB,CAC1E,GAAI,CACF,IAAMC,EAAW,MAAM,MAAM,KAAK,OAAO,YAAa,CACpD,OAAQ,OACR,QAAS,CACP,eAAgB,mBAChB,cAAiB,UAAU,KAAK,OAAO,MAAM,GAC7C,kBAAmB,OACrB,EACA,KAAM,KAAK,UAAU,CAAE,OAAAF,CAAO,CAAC,CACjC,CAAC,EAED,GAAI,CAACE,EAAS,GACZ,MAAM,IAAI,MAAM,cAAcA,EAAS,MAAM,IAAIA,EAAS,UAAU,EAAE,EAGpE,KAAK,OAAO,OACd,QAAQ,IAAI,0BAA0BF,EAAO,MAAM,SAAS,CAEhE,OAASP,EAAO,CACd,GAAIQ,EAAUE,EAAoB,CAEhC,IAAMC,EAAQC,EAAiB,KAAK,IAAI,EAAGJ,EAAU,CAAC,EACtD,OAAI,KAAK,OAAO,OACd,QAAQ,IAAI,mCAAmCA,CAAO,UAAUG,CAAK,IAAI,EAE3E,MAAM,IAAI,QAAQE,GAAW,WAAWA,EAASF,CAAK,CAAC,EAChD,KAAK,UAAUJ,EAAQC,EAAU,CAAC,CAC3C,CACA,MAAMR,CACR,CACF,CAKQ,eAAec,EAA2D,CAChF,GAAKA,EACL,OAAO,MAAM,QAAQA,CAAM,EAAIA,EAAO,CAAC,EAAIA,CAC7C,CAKA,SAAU,CACJ,KAAK,aACP,aAAa,KAAK,UAAU,EAC5B,KAAK,WAAa,MAGpB,KAAK,MAAM,EAAE,MAAM,IAAM,CAAC,CAAC,CAC7B,CACF,EH1LA,IAAIC,EAAiC,KAgB9B,SAASC,EAAwBC,EAA0B,CAEhE,OAAKF,IACHA,EAAU,IAAIG,EAAeD,CAAM,GAG9B,eAA0BE,EAAsB,CACrD,IAAMC,EAAY,KAAK,IAAI,EAE3B,GAAI,CAEF,IAAMC,EAAWF,EAAQ,QAAQ,SAEjC,GAAIF,EAAO,SACaA,EAAO,QAAQ,KAAKK,GACpCA,EAAQ,SAAS,GAAG,EACR,IAAI,OAAOA,EAAQ,QAAQ,MAAO,IAAI,CAAC,EACxC,KAAKD,CAAQ,EAErBA,EAAS,WAAWC,CAAO,CACnC,EAGC,OAAO,eAAa,KAAK,EAI7B,GAAIL,EAAO,SASL,CARkBA,EAAO,QAAQ,KAAKK,GACpCA,EAAQ,SAAS,GAAG,EACR,IAAI,OAAOA,EAAQ,QAAQ,MAAO,IAAI,CAAC,EACxC,KAAKD,CAAQ,EAErBA,EAAS,WAAWC,CAAO,CACnC,EAGC,OAAO,eAAa,KAAK,EAK7B,IAAMC,EAAYJ,EAAQ,QAAQ,IAAI,YAAY,EAC5CK,EAAYC,EAAgBF,CAAS,EAE3C,GAAI,CAACC,EAAU,aAAe,CAACA,EAAU,QACvC,OAAO,eAAa,KAAK,EAIvBP,EAAO,mBACT,MAAMA,EAAO,kBAAkBE,EAASK,EAAU,OAAO,EAI3D,IAAME,EAAW,eAAa,KAAK,EAG/BT,EAAO,oBACTS,EAAS,QAAQ,IAAI,wBAAyB,MAAM,EACpDA,EAAS,QAAQ,IAAI,oBAAqBF,EAAU,QAAQ,GAAG,EAC/DE,EAAS,QAAQ,IAAI,uBAAwBF,EAAU,QAAQ,OAAO,GAIxE,IAAMG,EAAWC,EAAuB,CACtC,QAAS,OAAO,YAAYT,EAAQ,QAAQ,QAAQ,CAAC,EACrD,IAAKA,EAAQ,IACb,OAAQA,EAAQ,MAClB,CAAC,EAGKU,EAAiB,KAAK,IAAI,EAAIT,EAG/BL,IACHA,EAAU,IAAIG,EAAeD,CAAM,GAIrC,IAAMa,EAAQf,EAAQ,YACpBS,EAAU,QACV,CACE,IAAKL,EAAQ,IACb,QAAS,OAAO,YAAYA,EAAQ,QAAQ,QAAQ,CAAC,EACrD,WAAYO,EAAS,OACrB,eAAAG,CACF,EACAF,CACF,EAGA,OAAAZ,EAAQ,MAAMe,CAAK,EAAE,MAAMC,GAAS,CAC9Bd,EAAO,OACT,QAAQ,MAAM,2CAA4Cc,CAAK,CAEnE,CAAC,EAEML,CAET,OAASK,EAAO,CAEd,OAAId,EAAO,OACT,QAAQ,MAAM,sCAAuCc,CAAK,EAErD,eAAa,KAAK,CAC3B,CACF,CACF,CAKO,SAASC,GAAiB,CAC3BjB,IACFA,EAAQ,QAAQ,EAChBA,EAAU,KAEd","names":["middleware_exports","__export","createCrawlerMiddleware","destroyTracker","__toCommonJS","import_server","AI_CRAWLERS","DEFAULT_API_ENDPOINT","BATCH_SIZE","BATCH_INTERVAL_MS","MAX_RETRY_ATTEMPTS","RETRY_DELAY_MS","detectAICrawler","userAgent","pattern","info","AI_CRAWLERS","lowerUA","aiPatterns","extractRequestMetadata","request","metadata","referer","accept","encoding","language","CrawlerTracker","config","DEFAULT_API_ENDPOINT","BATCH_SIZE","BATCH_INTERVAL_MS","error","event","fullEvent","crawler","request","metadata","url","events","attempt","response","MAX_RETRY_ATTEMPTS","delay","RETRY_DELAY_MS","resolve","header","tracker","createCrawlerMiddleware","config","CrawlerTracker","request","startTime","pathname","pattern","userAgent","detection","detectAICrawler","response","metadata","extractRequestMetadata","responseTimeMs","event","error","destroyTracker"]}