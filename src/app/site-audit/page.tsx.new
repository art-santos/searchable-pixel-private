'use client'

import { useState, useEffect } from 'react'

interface IssueItem {
  type: 'critical' | 'warning' | 'info'
  message: string
  context?: string
  fixSuggestion?: string
  url?: string
}

interface PageDataInCrawl {
  id: string
  url: string
  status_code: number
  title?: string
  ai_visibility_score?: number
  aeo_score?: number
  seo_score?: number
  meta_description?: string
  is_document?: boolean
  issues?: IssueItem[]
  has_schema?: boolean
}

interface CrawlData {
  siteUrl: string
  status: string
  completed_at?: string
  started_at: string
  totalPages: number
  crawledPages?: number
  aeoScore?: number
  seoScore?: number
  issues: { critical: number; warning: number; info: number }
  metricScores: {
    aiVisibility: number
    seo?: number
    contentQuality?: number
    technical?: number
    performance?: number
    mediaAccessibility?: number
  }
  pages?: PageDataInCrawl[]
  screenshots?: { url: string; screenshot_url: string }[]
  ai_summary_markdown?: string
}
import { Button } from "@/components/ui/button"
import { Card, CardContent, CardHeader, CardTitle, CardDescription } from "@/components/ui/card"
import { Badge } from "@/components/ui/badge"
import { Input } from "@/components/ui/input"
import { Progress } from "@/components/ui/progress"
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs"
import { Checkbox } from "@/components/ui/checkbox"
import { 
  Search, 
  AlertTriangle, 
  CheckCircle2, 
  XCircle,
  HelpCircle,
  MessageSquare, 
  ArrowUpRight,
  FileText,
  Rocket,
  Bot,
  Download,
  Globe,
  BarChart3,
  Link,
  ExternalLink,
  LayoutGrid,
  Clock,
  Zap,
  FileWarning,
  Slash,
  Image,
  FileDown,
  Settings,
  ScreenShare
} from 'lucide-react'
import { useToast } from "@/hooks/use-toast"

export default function SiteAudit() {
  const [siteUrl, setSiteUrl] = useState('')
  const [isCrawling, setIsCrawling] = useState(false)
  const [crawlProgress, setCrawlProgress] = useState(0)
  const [crawlComplete, setCrawlComplete] = useState(false)
  const [crawlData, setCrawlData] = useState<any>(null)
  const [crawlId, setCrawlId] = useState<string | null>(null)
  const [error, setError] = useState<string | null>(null)
  const { toast } = useToast()
  
  // Add options for enhanced features
  const [showAdvancedOptions, setShowAdvancedOptions] = useState(false)
  const [maxPages, setMaxPages] = useState(100)
  const [includeDocuments, setIncludeDocuments] = useState(true)
  const [checkMediaAccessibility, setCheckMediaAccessibility] = useState(true)
  const [performInteractiveActions, setPerformInteractiveActions] = useState(false)
  
  // Add a timeout state to detect issues with long-running crawls
  const [crawlStartTime, setCrawlStartTime] = useState<number | null>(null)
  const [showTimeoutWarning, setShowTimeoutWarning] = useState(false)
  
  // Add page filter state
  const [pageFilter, setPageFilter] = useState<string | null>(null)
  
  // Poll for crawl status updates
  useEffect(() => {
    if (!crawlId || crawlComplete) return;
    
    // Set the start time when polling begins
    if (!crawlStartTime) {
      setCrawlStartTime(Date.now());
    }
    
    console.log('Setting up polling for crawl ID:', crawlId);
    
    // Show initial activity
    toast({
      title: "Crawl processing",
      description: "The crawler is initializing. This may take a moment.",
    });
    
    // Check for timeout after 2 minutes
    if (crawlStartTime && Date.now() - crawlStartTime > 120000 && !showTimeoutWarning) {
      setShowTimeoutWarning(true);
      toast({
        title: "Crawl taking longer than expected",
        description: "The website may be blocking our crawler or is very slow to respond. You may want to try a different site.",
        variant: "destructive",
        duration: 10000
      });
    }
    
    // Auto-increment progress slightly to show activity
    const minProgressInterval = setInterval(() => {
      setCrawlProgress(prev => {
        // Only auto-increment if below 90% and no significant change in last 10 seconds
        if (prev < 90) {
          return prev + 0.1;
        }
        return prev;
      });
    }, 1000);
    
    // Poll for status updates
    const statusInterval = setInterval(async () => {
      try {
        console.log("Polling status for crawl ID:", crawlId);
        
        const response = await fetch(`/api/site-audit/status/${crawlId}`);
        console.log("Status response status:", response.status);
        
        if (!response.ok) {
          console.error("Status API returned error:", response.status);
          throw new Error('Failed to get crawl status');
        }
        
        const data = await response.json();
        console.log("Crawl status data:", data);
        
        // Only update if the returned progress is higher than current
        if (data.progress > crawlProgress) {
          console.log(`Updating progress: ${crawlProgress} -> ${data.progress}`);
          setCrawlProgress(data.progress || 0);
        }
        
        // Fetch partial results if crawl is in progress
        if (data.status === 'started' || data.status === 'processing') {
          console.log("Fetching partial results for crawl in progress");
          fetchPartialResults();
        }
        
        if (data.status === 'completed') {
          console.log("Crawl completed, fetching final results");
          clearInterval(statusInterval);
          clearInterval(minProgressInterval);
          setCrawlProgress(100); // Ensure 100% when complete
          fetchCrawlResults();
        }
      } catch (error) {
        console.error('Error checking crawl status:', error);
        
        // Don't stop polling on errors
        if (error.message === 'Failed to get crawl status' && error.response?.status === 404) {
          clearInterval(statusInterval);
          clearInterval(minProgressInterval);
          setError('Crawl not found');
        }
      }
    }, 3000);
    
    return () => {
      console.log("Clearing polling intervals");
      clearInterval(statusInterval);
      clearInterval(minProgressInterval);
    };
  }, [crawlId, crawlComplete]);
  
  // Function to fetch partial results
  const fetchPartialResults = async () => {
    if (!crawlId) return;
    
    try {
      console.log(`Fetching partial results for crawl ${crawlId}`);
      const response = await fetch(`/api/site-audit/partial-results/${crawlId}`);
      
      if (!response.ok) {
        console.log("Partial results not available yet, status:", response.status);
        // Create a minimal placeholder data structure if we don't have real data yet
        if (!crawlData) {
          setCrawlData({
            status: 'processing',
            totalPages: 0,
            crawledPages: 0,
            aeoScore: 0,
            issues: { critical: 0, warning: 0, info: 0 },
            pages: [],
            metricScores: {
              aiVisibility: 0,
              contentQuality: 0,
              technical: 0,
              performance: 0
            },
            isPartial: true
          });
        }
        return;
      }
      
      const data = await response.json();
      console.log("Partial crawl results:", data);
      
      if (data.pages && data.pages.length > 0) {
        console.log(`Received ${data.pages.length} pages in partial results`);
      }
      
      // Update the UI with partial results
      setCrawlData(data);
    } catch (error) {
      console.error('Error fetching partial results:', error);
      // Don't show error to user as this is a background update
      // Create fallback data if we don't have any yet
      if (!crawlData) {
        setCrawlData({
          status: 'processing',
          totalPages: 0,
          crawledPages: 0,
          aeoScore: 0,
          issues: { critical: 0, warning: 0, info: 0 },
          pages: [],
          metricScores: {
            aiVisibility: 0,
            contentQuality: 0,
            technical: 0,
            performance: 0
          },
          isPartial: true
        });
      }
    }
  };
  
  // Function to start a crawl
  const startCrawl = async () => {
    if (!siteUrl) return;
    
    // Clear previous errors
    setError(null);
    
    // Validate URL format
    if (!validateUrl(siteUrl)) {
      setError('Please enter a valid website URL (e.g., example.com)');
      return;
    }
    
    try {
      console.log('Starting crawl for URL:', siteUrl);
      setIsCrawling(true);
      setCrawlProgress(0);
      setCrawlComplete(false);
      setCrawlData(null);
      setCrawlId(null);
      setCrawlStartTime(Date.now());
      setShowTimeoutWarning(false);
      
      console.log('Sending request to /api/site-audit/start with options:', {
        siteUrl,
        maxPages,
        includeDocuments,
        checkMediaAccessibility,
        performInteractiveActions
      });
      
      const response = await fetch('/api/site-audit/start', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          siteUrl,
          maxPages,
          includeDocuments,
          checkMediaAccessibility,
          performInteractiveActions
        }),
      });
      
      console.log('Response status:', response.status);
      
      // Get detailed error message if response is not ok
      if (!response.ok) {
        const errorData = await response.json();
        console.error('Server error response:', errorData);
        const errorMessage = errorData.error || 'Failed to start crawl';
        throw new Error(errorMessage);
      }
      
      const data = await response.json();
      console.log('Crawl started successfully with ID:', data.crawlId);
      setCrawlId(data.crawlId);
      
      toast({
        title: "Crawl started",
        description: "Your site is being crawled with Firecrawl. This may take a few minutes.",
      });
      
    } catch (error) {
      console.error('Error starting crawl:', error);
      setError(error.message || 'Failed to start the site audit. Please try again.');
      setIsCrawling(false);
      
      toast({
        title: "Crawl failed",
        description: error.message || "There was an error starting the crawl.",
        variant: "destructive",
      });
    }
  };
  
  // Function to fetch crawl results
  const fetchCrawlResults = async () => {
    try {
      console.log(`Fetching final results for crawl ${crawlId}`);
      const response = await fetch(`/api/site-audit/results/${crawlId}`);
      
      if (!response.ok) {
        console.error("Error getting final results, status:", response.status);
        throw new Error('Failed to get crawl results');
      }
      
      const data = await response.json();
      console.log("Final crawl results:", data);
      
      if (data.status === 'completed') {
        console.log("Setting crawl as complete with data");
        setCrawlComplete(true);
        setCrawlData(data);
        setIsCrawling(false);
        
        toast({
          title: "Crawl completed",
          description: "Your site audit is complete.",
        });
      } else {
        // Keep waiting if status is still processing
        console.log("Results not complete yet, trying again in 3s");
        setTimeout(fetchCrawlResults, 3000);
      }
    } catch (error) {
      console.error('Error fetching crawl results:', error);
      setError('Failed to fetch the audit results. Please try again later.');
      setIsCrawling(false);
      
      toast({
        title: "Error fetching results",
        description: error.message || "There was an error retrieving the crawl results.",
        variant: "destructive",
      });
    }
  };
  
  // Helper function to get issue badge color
  const getIssueBadgeClass = (type: string) => {
    switch(type) {
      case 'critical':
        return 'bg-red-900/30 text-red-400 border-red-900/50';
      case 'warning':
        return 'bg-yellow-900/30 text-yellow-400 border-yellow-900/50';
      case 'info':
      default:
        return 'bg-blue-900/30 text-blue-400 border-blue-900/50';
    }
  };
  
  // Helper function to get status code badge color
  const getStatusBadgeClass = (statusCode: number) => {
    if (statusCode >= 200 && statusCode < 300) {
      return 'bg-green-900/30 text-green-400 border-green-900/50';
    } else if (statusCode >= 300 && statusCode < 400) {
      return 'bg-yellow-900/30 text-yellow-400 border-yellow-900/50';
    } else {
      return 'bg-red-900/30 text-red-400 border-red-900/50';
    }
  };
  
  // Helper function to get visibility badge
  const getVisibilityBadge = (score: number) => {
    if (score >= 80) {
      return <Badge className="bg-green-900/30 text-green-400 border-green-900/50">Good</Badge>;
    } else if (score >= 50) {
      return <Badge className="bg-yellow-900/30 text-yellow-400 border-yellow-900/50">Moderate</Badge>;
    } else if (score > 0) {
      return <Badge className="bg-red-900/30 text-red-400 border-red-900/50">Poor</Badge>;
    } else {
      return <Badge className="bg-[#222222] text-gray-400 border-[#333333]/30">None</Badge>;
    }
  };
  
  // Function to validate URL
  const validateUrl = (url: string) => {
    if (!url) return false;
    
    // Remove protocol for basic validation
    const cleanUrl = url.replace(/^https?:\/\//, '');
    
    // Check for valid domain format (basic check)
    return /^[a-zA-Z0-9][a-zA-Z0-9-]+\.[a-zA-Z]{2,}/.test(cleanUrl);
  };
  
  // Add a cancel function
  const cancelCrawl = () => {
    if (!crawlId) return;
    
    // Clear intervals and reset UI state
    setCrawlProgress(0);
    setIsCrawling(false);
    setCrawlComplete(false);
    setCrawlData(null);
    setCrawlId(null);
    setCrawlStartTime(null);
    setShowTimeoutWarning(false);
    
    toast({
      title: "Crawl cancelled",
      description: "You can try with a different website.",
    });
  };
  
  // Add function to filter pages
  const getFilteredPages = () => {
    if (!crawlData || !crawlData.pages) return [];
    
    if (!pageFilter) return crawlData.pages;
    
    switch (pageFilter) {
      case 'document':
        return crawlData.pages.filter(page => page.is_document);
      case 'issues':
        return crawlData.pages.filter(page => page.issues && page.issues.length > 0);
      case 'schema':
        return crawlData.pages.filter(page => page.has_schema);
      default:
        return crawlData.pages;
    }
  };
  
  // Function to get status code breakdown
  const getStatusCodeBreakdown = () => {
    if (!crawlData || !crawlData.pages) return [];
    
    const statusCounts = {};
    
    // Count status codes
    crawlData.pages.forEach(page => {
      const statusCode = Math.floor(page.status_code / 100) * 100;
      if (!statusCounts[statusCode]) {
        statusCounts[statusCode] = 0;
      }
      statusCounts[statusCode]++;
    });
    
    // Convert to array for rendering
    return Object.entries(statusCounts)
      .map(([status, count]) => ({ status: parseInt(status), count }))
      .sort((a, b) => a.status - b.status);
  };
  
  // Computed values for recommendations
  const issueCount = crawlData 
    ? crawlData.issues.critical + crawlData.issues.warning + crawlData.issues.info 
    : 0;

  // Function to get critical issues for the recommendations panel
  const getCriticalIssues = () => {
    if (!crawlData || !crawlData.pages) return [];
    
    const allIssues = [];
    
    // Collect all critical issues
    for (const page of crawlData.pages) {
      if (page.issues && page.issues.length > 0) {
        const criticalIssues = page.issues
          .filter(issue => issue.type === 'critical')
          .map(issue => ({
            ...issue,
            pageUrl: page.url
          }));
        allIssues.push(...criticalIssues);
      }
    }
    
    // Return top 3 critical issues
    return allIssues.slice(0, 3);
  };
  
  return (
    <main className="flex flex-1 flex-col gap-8 p-8 overflow-auto bg-[#0c0c0c] bg-[radial-gradient(#222222_0.7px,transparent_0.7px)] bg-[size:24px_24px]">
      {/* Debug info - Remove this in production */}
      <div className="bg-[#161616] p-4 rounded border border-[#222222] text-xs text-gray-300">
        <h3 className="font-bold mb-2 text-white">Debug Info:</h3>
        <div>isCrawling: {isCrawling ? 'true' : 'false'}</div>
        <div>crawlProgress: {crawlProgress}</div>
        <div>crawlComplete: {crawlComplete ? 'true' : 'false'}</div>
        <div>crawlId: {crawlId || 'null'}</div>
        <div>error: {error || 'null'}</div>
        <div>crawlData: {crawlData ? `has ${crawlData.pages?.length || 0} pages` : 'null'}</div>
        <button 
          onClick={() => console.log('Current state:', { isCrawling, crawlProgress, crawlComplete, crawlId, error, crawlData })}
          className="mt-2 px-2 py-1 bg-[#222222] text-white rounded"
        >
          Log State
        </button>
      </div>
    </main>
  );
} 